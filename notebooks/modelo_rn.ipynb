{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "from src.dataframe import importDfPickle\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adadelta, Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=importDfPickle(\"./output/df_30mil.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir la columna en una numpy que tenga la dimension filas, 50,50,3\n",
    "X=np.asarray(list(df['image']))\n",
    "y=np.asarray(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 50, 50, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Summarize current state of dataset\"\"\"\n",
    "    print('Train images shape:', X_train.shape)\n",
    "    print('Train labels shape:', y_train.shape)\n",
    "    print('Test images shape:', X_test.shape)\n",
    "    print('Test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (24000, 50, 50, 3)\n",
      "Train labels shape: (24000,)\n",
      "Test images shape: (6000, 50, 50, 3)\n",
      "Test labels shape: (6000,)\n"
     ]
    }
   ],
   "source": [
    "data_summary(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Incoming data is in uint8. Cast the input data images to be floats in range [0.0-1.0]  \\nX_train = X_train.astype('float32')\\nX_test = X_test.astype('float32')\\nX_train /= 255\\nX_test /= 255\\n\\nprint('x_train shape:', X_train.shape)\\nprint(X_train.shape[0], 'train samples')\\nprint(X_test.shape[0], 'test samples')\\n# convert class vectors to binary class matrices\\ny_train = keras.utils.to_categorical(y_train, 2)\\ny_test = keras.utils.to_categorical(y_test, 2)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Incoming data is in uint8. Cast the input data images to be floats in range [0.0-1.0]  \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(50,50,3)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the neural network proposed architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/14\n",
      "28000/28000 [==============================] - 198s 7ms/sample - loss: 39.5459 - accuracy: 0.5998 - val_loss: 12.5387 - val_accuracy: 0.7116\n",
      "Epoch 2/14\n",
      "28000/28000 [==============================] - 198s 7ms/sample - loss: 30.4263 - accuracy: 0.6049 - val_loss: 9.1551 - val_accuracy: 0.7131\n",
      "Epoch 3/14\n",
      "28000/28000 [==============================] - 198s 7ms/sample - loss: 23.2340 - accuracy: 0.6139 - val_loss: 5.8500 - val_accuracy: 0.7186\n",
      "Epoch 4/14\n",
      "28000/28000 [==============================] - 196s 7ms/sample - loss: 17.7247 - accuracy: 0.6167 - val_loss: 3.9644 - val_accuracy: 0.7147\n",
      "Epoch 5/14\n",
      "28000/28000 [==============================] - 196s 7ms/sample - loss: 12.8590 - accuracy: 0.6294 - val_loss: 3.2512 - val_accuracy: 0.7127\n",
      "Epoch 6/14\n",
      "28000/28000 [==============================] - 197s 7ms/sample - loss: 9.2558 - accuracy: 0.6269 - val_loss: 2.1868 - val_accuracy: 0.7124\n",
      "Epoch 7/14\n",
      "28000/28000 [==============================] - 196s 7ms/sample - loss: 6.2956 - accuracy: 0.6311 - val_loss: 0.8521 - val_accuracy: 0.7124\n",
      "Epoch 8/14\n",
      "28000/28000 [==============================] - 197s 7ms/sample - loss: 4.3744 - accuracy: 0.6327 - val_loss: 0.5104 - val_accuracy: 0.7457\n",
      "Epoch 9/14\n",
      "28000/28000 [==============================] - 221s 8ms/sample - loss: 3.0014 - accuracy: 0.6308 - val_loss: 0.6113 - val_accuracy: 0.7101\n",
      "Epoch 10/14\n",
      "28000/28000 [==============================] - 204s 7ms/sample - loss: 2.0002 - accuracy: 0.6304 - val_loss: 0.6212 - val_accuracy: 0.7331\n",
      "Epoch 11/14\n",
      "28000/28000 [==============================] - 200s 7ms/sample - loss: 1.4519 - accuracy: 0.6282 - val_loss: 0.6223 - val_accuracy: 0.7147\n",
      "Epoch 12/14\n",
      "28000/28000 [==============================] - 197s 7ms/sample - loss: 1.1193 - accuracy: 0.6300 - val_loss: 0.6237 - val_accuracy: 0.7127\n",
      "Epoch 13/14\n",
      "28000/28000 [==============================] - 197s 7ms/sample - loss: 0.9256 - accuracy: 0.6296 - val_loss: 0.6232 - val_accuracy: 0.7123\n",
      "Epoch 14/14\n",
      "28000/28000 [==============================] - 209s 7ms/sample - loss: 0.8380 - accuracy: 0.6344 - val_loss: 0.6127 - val_accuracy: 0.7126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5767ba5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the NN\n",
    "batch_size = 220\n",
    "epochs = 14\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6126549941471645\n",
      "Test accuracy: 0.71257144\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model-Seq220,14,acu73.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model-Seq220,14,acu73.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def resizeImages(img_path,size=(50,50)):\n",
    "    \"resize all images to 50x50\"\n",
    "    image = cv2.imread(img_path)\n",
    "    resized = cv2.resize(image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    #print('resized image')\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs -> Benign:0.50565 Malignant:0.49435\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img = X_test[31].astype('float32')\n",
    "pred = model.predict(np.expand_dims(img,axis=0))[0]\n",
    "print(\"Probs -> Benign:{0:.5f} Malignant:{1:.5f}\".format(pred[0],pred[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./images/16896_idx5_x51_y151_class0.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = resizeImages(file).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs -> Benign:0.62560 Malignant:0.37440\n"
     ]
    }
   ],
   "source": [
    "pred_nueva=model.predict(np.expand_dims(im,axis=0))[0]\n",
    "print(\"Probs -> Benign:{0:.5f} Malignant:{1:.5f}\".format(pred_nueva[0],pred_nueva[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45712334, 0.54287666], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNewImage(path):\n",
    "    im = resizeImages(path).astype('float32')\n",
    "    pred_nueva=model.predict(np.expand_dims(im,axis=0))[0]\n",
    "    return \"Probs -> Benign:{0:.5f} Malignant:{1:.5f}\".format(pred_nueva[0],pred_nueva[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2='./images/16896_idx5_x201_y1101_class1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=predictNewImage(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Probs -> Benign:0.49333 Malignant:0.50667'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4=predictNewImage('./images/16896_idx5_x201_y1051_class1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Probs -> Benign:0.58506 Malignant:0.41494'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[241, 240, 243], [241, 240, 243], [241, 240,...</td>\n",
       "      <td>images/0/10269_idx5_x1101_y901_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[200, 182, 232], [210, 193, 235], [220, 211,...</td>\n",
       "      <td>images/0/9254_idx5_x1551_y1851_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[206, 181, 227], [235, 230, 233], [238, 235,...</td>\n",
       "      <td>images/0/9259_idx5_x2401_y951_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[226, 210, 241], [235, 232, 241], [238, 232,...</td>\n",
       "      <td>images/0/12930_idx5_x951_y1201_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[242, 241, 241], [236, 236, 243], [150, 108,...</td>\n",
       "      <td>images/0/9227_idx5_x901_y1251_class0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              image  \\\n",
       "0      1  [[[241, 240, 243], [241, 240, 243], [241, 240,...   \n",
       "1      1  [[[200, 182, 232], [210, 193, 235], [220, 211,...   \n",
       "2      1  [[[206, 181, 227], [235, 230, 233], [238, 235,...   \n",
       "3      1  [[[226, 210, 241], [235, 232, 241], [238, 232,...   \n",
       "4      1  [[[242, 241, 241], [236, 236, 243], [150, 108,...   \n",
       "\n",
       "                                        path  \n",
       "0  images/0/10269_idx5_x1101_y901_class0.png  \n",
       "1  images/0/9254_idx5_x1551_y1851_class0.png  \n",
       "2   images/0/9259_idx5_x2401_y951_class0.png  \n",
       "3  images/0/12930_idx5_x951_y1201_class0.png  \n",
       "4   images/0/9227_idx5_x901_y1251_class0.png  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
